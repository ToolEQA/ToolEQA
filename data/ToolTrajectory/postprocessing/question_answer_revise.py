# é€šè¿‡è¿™ä¸ªè„šæœ¬å®ç°thought code observationçš„ç”Ÿæˆ
import os
import json
from collections import defaultdict
from data.ToolTrajectory.generator_deerapi import requests_api
from src.tools.tool_box import get_tool_box, show_tool_descriptions
import re
import pandas as pd


def normalize_choice(choice):
    """æŠŠé”™è¯¯ç¼–ç çš„å­—ç¬¦ä¸²ä¿®å¤æˆæ­£å¸¸çš„ en-dash"""
    return choice.replace("Ã¢â‚¬â€œ", "â€“").replace("\u00e2\u0080\u0093", "â€“")

def load_excel(excel_path):
    """è¯»å–å¹¶æ•´ç† excel"""
    df = pd.read_csv(excel_path)
    df.columns = df.columns.str.strip().str.lower()
    df["scene"] = df["scene_id"].astype(str).str.strip()
    df["question"] = df["question"].astype(str).str.strip()
    df["answer"] = df["answer"].astype(str).str.strip()
    df["choices"] = df["choices"].astype(str).str.strip()
    return df

def main(excel_path, data_path, output_path, question_type):
    # è¯»å–æ•°æ®
    with open(data_path, "r", encoding="utf-8") as f:
        json_data = json.load(f)

    df = load_excel(excel_path)

    updated_data = []

    for item in json_data:
        qt = item.get("question_type")
        scene = str(item.get("scene", "")).strip()
        question = str(item.get("question", "")).strip()

        subset = df[df["scene"] == scene]
        match = subset[subset["question"] == question]

        # é»˜è®¤ä¿ç•™
        keep = True

        if question_type == "size":

            if qt == "attribute-size":
                if not match.empty:
                    row = match.iloc[0]
                    new_answer = row["answer"]

                    if new_answer == "D":
                        print(f"ğŸ—‘ï¸ åˆ é™¤: scene={scene}, question={question}, answer=D")
                        keep = False  # ä¸ä¿ç•™
                    else:
                        original_answer = item["answer"]
                        item["answer"] = new_answer
                        print(f"âœ… æ›´æ–° attribute-size: scene={scene}, question={question}, answer={new_answer}, original_answer={original_answer}")
                else:
                    keep = False  # ä¸ä¿ç•™
                    print(f"âš ï¸ attribute-size æœªæ‰¾åˆ°åŒ¹é…: scene={scene}, question={question}")

        elif question_type == "distance":

            if qt == "distance-distance":
                if not match.empty:
                    row = match.iloc[0]
                    new_answer = row["answer"]
                    choices_str = row["choices"]
                    original_answer = item["answer"]
                    item["answer"] = new_answer

                    try:
                        choices_list = json.loads(choices_str)
                        choices_list = [normalize_choice(c) for c in choices_list]
                        item["proposals"] = choices_list
                        print(f"âœ… æ›´æ–° distance-distance: scene={scene}, question={question}, answer={new_answer}, proposals={choices_list}, original_answer={original_answer}")
                    except Exception as e:
                        print(f"âš ï¸ è§£æ choices å‡ºé”™: scene={scene}, question={question}, choices={choices_str}, é”™è¯¯: {e}")
                else:
                    keep = False  # ä¸ä¿ç•™
                    print(f"âš ï¸ distance-distance æœªæ‰¾åˆ°åŒ¹é…: scene={scene}, question={question}")

        # å¦‚æœæ ‡è®°ä¸ºä¿ç•™ï¼Œå†™å›
        if keep:
            updated_data.append(item)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(updated_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ æ›´æ–°å®Œæˆï¼Œä¿å­˜ä¸º {output_path}")




if __name__=="__main__":
    data_path = "trajectory.json"
    output_path_temp = "output/trajectory_temp.json"
    excel_path_size = "data/size_cleaned_ans.csv"
    question_type = "size"
    main(excel_path_size, data_path, output_path_temp, question_type)


    excel_path_distance = "data/distance_cleaned_ans_options.csv"
    question_type = "distance"  
    output_path = "output/trajectory_update.json"
    main(excel_path_distance, output_path_temp, output_path, question_type)








