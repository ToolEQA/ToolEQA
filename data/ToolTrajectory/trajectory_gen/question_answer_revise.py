# é€šè¿‡è¿™ä¸ªè„šæœ¬å®ç°thought code observationçš„ç”Ÿæˆ
import os
import json
from collections import defaultdict
from data.ToolTrajectory.generator_deerapi import requests_api
from src.tools.tool_box import get_tool_box, show_tool_descriptions
import re
import pandas as pd
import ast


def normalize_choice(choice):
    """æŠŠé”™è¯¯ç¼–ç çš„å­—ç¬¦ä¸²ä¿®å¤æˆæ­£å¸¸çš„ en-dash"""
    return choice.replace("Ã¢â‚¬â€œ", "â€“").replace("\u00e2\u0080\u0093", "â€“")

def load_excel(excel_path):
    """è¯»å–å¹¶æ•´ç† excel"""
    df = pd.read_csv(excel_path)
    df.columns = df.columns.str.strip().str.lower()
    df["scene"] = df["scene_id"].astype(str).str.strip()
    df["question"] = df["question"].astype(str).str.strip()
    df["answer"] = df["answer"].astype(str).str.strip()
    df["choices"] = df["choices"].astype(str).str.strip()
    return df

def main(excel_path, data_path, output_path, question_type):
    # è¯»å–æ•°æ®
    with open(data_path, "r", encoding="utf-8") as f:
        json_data = json.load(f)

    df = load_excel(excel_path)

    updated_data = []

    for item in json_data:
        qt = item.get("question_type")
        scene = str(item.get("scene", "")).strip()
        question = str(item.get("question", "")).strip()

        subset = df[df["scene"] == scene]
        match = subset[subset["question"] == question]

        # é»˜è®¤ä¿ç•™
        keep = True

        if question_type == "size":

            if qt == "attribute-size":
                if not match.empty:
                    row = match.iloc[0]
                    new_answer = row["answer"]

                    if new_answer == "D":
                        print(f"ğŸ—‘ï¸ åˆ é™¤: scene={scene}, question={question}, answer=D")
                        keep = False  # ä¸ä¿ç•™
                    else:
                        original_answer = item["answer"]
                        item["answer"] = new_answer
                        print(f"âœ… æ›´æ–° attribute-size: scene={scene}, question={question}, answer={new_answer}, original_answer={original_answer}")
                else:
                    keep = False  # ä¸ä¿ç•™
                    print(f"âš ï¸ attribute-size æœªæ‰¾åˆ°åŒ¹é…: scene={scene}, question={question}")

        elif question_type == "distance":

            if qt == "distance-distance":
                if not match.empty:
                    row = match.iloc[0]
                    new_answer = row["answer"]
                    choices_str = row["choices"]
                    original_answer = item["answer"]
                    item["answer"] = new_answer

                    try:
                        # choices_list = json.loads(choices_str)
                        choices_list = ast.literal_eval(choices_str)
                        choices_list = [normalize_choice(c) for c in choices_list]
                        item["proposals"] = choices_list
                        print(f"âœ… æ›´æ–° distance-distance: scene={scene}, question={question}, answer={new_answer}, proposals={choices_list}, original_answer={original_answer}")
                    except Exception as e:
                        print(f"âš ï¸ è§£æ choices å‡ºé”™: scene={scene}, question={question}, choices={choices_list}, é”™è¯¯: {e}")
                else:
                    keep = False  # ä¸ä¿ç•™
                    print(f"âš ï¸ distance-distance æœªæ‰¾åˆ°åŒ¹é…: scene={scene}, question={question}")

        # å¦‚æœæ ‡è®°ä¸ºä¿ç•™ï¼Œå†™å›
        if keep:
            updated_data.append(item)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(updated_data, f, ensure_ascii=False, indent=4)

    print(f"\nğŸ‰ æ›´æ–°å®Œæˆï¼Œä¿å­˜ä¸º {output_path}")



def check_all_single_locations(file_path, column='locations'):
    """
    æ£€æŸ¥ Excel ä¸­æŒ‡å®šåˆ—æ˜¯å¦æ‰€æœ‰è¡Œæå–å‡ºæ¥çš„æ•°å­—åªæœ‰ä¸€ä¸ªã€‚
    æå–è§„åˆ™ï¼šåŒ¹é… 'stair (æ•°å­—)' ä¸­çš„æ•°å­—ã€‚
    """
    df = pd.read_csv(file_path)

    for val in df[column]:
        # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        if not isinstance(val, str):
            return False

        # ç”¨æ­£åˆ™æå–æ‹¬å·é‡Œçš„æ•°å­—
        matches = re.findall(r'\((\d+)\)', val)

        if len(matches) != 1:
            return False

    return True




def count_json_items(path):
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return len(data)


def check_fields_in_json(json_path, fields):
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    missing_records = []  # è®°å½•ç¼ºå°‘å­—æ®µçš„æ¡ç›®
    for idx, item in enumerate(data):
        missing = [field for field in fields if field not in item]
        if missing:
            missing_records.append((idx, missing))

    if not missing_records:
        print(f"âœ… æ‰€æœ‰è®°å½•éƒ½åŒ…å«å­—æ®µ {fields}")
    else:
        print(f"âš ï¸ ä»¥ä¸‹è®°å½•ç¼ºå°‘å­—æ®µï¼š")
        for idx, missing in missing_records:
            print(f"  ç¬¬ {idx} æ¡è®°å½•ç¼ºå°‘å­—æ®µ: {missing}")
        print(f"å…± {len(missing_records)} æ¡è®°å½•ç¼ºå°‘å­—æ®µ")


if __name__=="__main__":
    # data_path = "trajectory.json"
    # output_path_temp = "output/trajectory_temp.json"
    # excel_path_size = "data/size_cleaned_ans.csv"
    # question_type = "size"
    # main(excel_path_size, data_path, output_path_temp, question_type)

    # output_path_temp = "output/trajectory_temp.json"
    # excel_path_distance = "data/distance_cleaned_ans_options.csv"
    # question_type = "distance"  
    # output_path = "output/trajectory_update.json"
    # main(excel_path_distance, output_path_temp, output_path, question_type)

    result = check_all_single_locations("status.csv")
    if result:
        print("âœ… æ‰€æœ‰è¡Œçš„ locations éƒ½æ˜¯å•å…ƒç´  listã€‚")
    else:
        print("âŒ æœ‰äº›è¡Œä¸æ˜¯å•å…ƒç´  listã€‚")



